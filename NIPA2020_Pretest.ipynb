{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NIPA2020_Pretest",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xexRfnrS2JwULvo4fipj8B7mz4zS0OV-",
      "authorship_tag": "ABX9TyOsLpEM3kzPKLm/VpcsIg6a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyeonhoonLee/NIPA2020/blob/main/NIPA2020_Pretest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqFeVB6bhen7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImExa3y4hl9P"
      },
      "source": [
        "seed = 1234\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 3e-4\n",
        "EPOCHS = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us1ZRzPxhMnF"
      },
      "source": [
        "data_path = '/content/drive/My Drive/DataCollection/NIPA2020/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXMw-cQ7hI8l",
        "outputId": "8c735c32-4d09-49e1-b546-15675216e00a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Data loading\n",
        "train_df = pd.read_csv('/content/drive/My Drive/DataCollection/NIPA2020/train.tsv', sep='\\t', names= [\"file_name\", \"Plant\", \"Disease\"])\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>Plant</th>\n",
              "      <th>Disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3_5_1123.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3_20_1048.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4_2_401.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4_7_740.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4_11_93.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       file_name  Plant  Disease\n",
              "0   3_5_1123.jpg      3        5\n",
              "1  3_20_1048.jpg      3       20\n",
              "2    4_2_401.jpg      4        2\n",
              "3    4_7_740.jpg      4        7\n",
              "4    4_11_93.jpg      4       11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_bsT68zrlpQ",
        "outputId": "f030dcb2-8bad-47be-db57-6987eaa94ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "train_df[\"Plant\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13    6400\n",
              "4     2400\n",
              "7     1600\n",
              "3     1600\n",
              "8     1600\n",
              "5      800\n",
              "11     800\n",
              "10     800\n",
              "Name: Plant, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lqJWd29txCr",
        "outputId": "b1c1cd5f-cbd7-4d49-82d3-42d3fb7636b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df['label'] = list(zip(train_df.Plant, train_df.Disease))\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>Plant</th>\n",
              "      <th>Disease</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3_5_1123.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>(3, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3_20_1048.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>(3, 20)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4_2_401.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>(4, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4_7_740.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>(4, 7)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4_11_93.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>(4, 11)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       file_name  Plant  Disease    label\n",
              "0   3_5_1123.jpg      3        5   (3, 5)\n",
              "1  3_20_1048.jpg      3       20  (3, 20)\n",
              "2    4_2_401.jpg      4        2   (4, 2)\n",
              "3    4_7_740.jpg      4        7   (4, 7)\n",
              "4    4_11_93.jpg      4       11  (4, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kDQqYhNMIuo",
        "outputId": "f7195fce-793a-4909-fca0-dbc37854f5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "train_df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 1)     800\n",
              "(3, 20)     800\n",
              "(13, 6)     800\n",
              "(4, 11)     800\n",
              "(13, 18)    800\n",
              "(4, 7)      800\n",
              "(5, 8)      800\n",
              "(8, 9)      800\n",
              "(13, 16)    800\n",
              "(10, 20)    800\n",
              "(13, 9)     800\n",
              "(8, 6)      800\n",
              "(3, 5)      800\n",
              "(11, 14)    800\n",
              "(13, 17)    800\n",
              "(7, 1)      800\n",
              "(7, 20)     800\n",
              "(13, 15)    800\n",
              "(4, 2)      800\n",
              "(13, 20)    800\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "690Bh9mIH_rn",
        "outputId": "d56b3ec3-9be7-47f3-90bc-41e17e37bfb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df.label = pd.factorize(train_df.label)[0]\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>Plant</th>\n",
              "      <th>Disease</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3_5_1123.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3_20_1048.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4_2_401.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4_7_740.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4_11_93.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       file_name  Plant  Disease  label\n",
              "0   3_5_1123.jpg      3        5      0\n",
              "1  3_20_1048.jpg      3       20      1\n",
              "2    4_2_401.jpg      4        2      2\n",
              "3    4_7_740.jpg      4        7      3\n",
              "4    4_11_93.jpg      4       11      4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHnmF_VZIoIx",
        "outputId": "b297d475-a3f0-4543-cf19-300955d665f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "train_df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15    800\n",
              "7     800\n",
              "8     800\n",
              "16    800\n",
              "1     800\n",
              "9     800\n",
              "17    800\n",
              "2     800\n",
              "10    800\n",
              "18    800\n",
              "3     800\n",
              "11    800\n",
              "19    800\n",
              "4     800\n",
              "12    800\n",
              "5     800\n",
              "13    800\n",
              "6     800\n",
              "14    800\n",
              "0     800\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cae7byDQlgMJ"
      },
      "source": [
        "from keras_preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4CIa6hXpk6f"
      },
      "source": [
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers, Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCniDMw9huGz"
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        # shear_range=0.2,\n",
        "        # zoom_range=0.2,\n",
        "        # rotation_range=15,\n",
        "        # width_shift_range=0.1,\n",
        "        # height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.2\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki57bLr9j3PR",
        "outputId": "a2240f08-0f3c-4ce7-c06c-1a4201443971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "train_generator=train_datagen.flow_from_dataframe(\n",
        "  dataframe=train_df,\n",
        "  directory=\"/content/drive/My Drive/DataCollection/NIPA2020/train\",\n",
        "  x_col=\"file_name\",\n",
        "  y_col=\"label\",\n",
        "  # y_col=[\"Plant\",\"Disease\"],\n",
        "  subset=\"training\",\n",
        "  batch_size=BATCH_SIZE,\n",
        "  seed=seed,\n",
        "  shuffle=True,\n",
        "  class_mode=\"raw\",\n",
        "  target_size=(128,128))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12800 validated image filenames.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 1 invalid image filename(s) in x_col=\"file_name\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idJhol3Enlnh",
        "outputId": "cd86705d-8467-454e-8e62-6d382df5af2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator=train_datagen.flow_from_dataframe(\n",
        "  dataframe=train_df,\n",
        "  directory=\"/content/drive/My Drive/DataCollection/NIPA2020/train\",\n",
        "  x_col=\"file_name\",\n",
        "  y_col=\"label\",\n",
        "  subset=\"validation\",\n",
        "  batch_size=BATCH_SIZE,\n",
        "  seed=seed,\n",
        "  shuffle=True,\n",
        "  class_mode=\"raw\",\n",
        "  target_size=(128,128))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3200 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUfAWQVsREBQ",
        "outputId": "e5eddd4f-8ee7-4305-bfa2-112a7c390236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# from keras.applications.densenet import DenseNet121\n",
        "# orig_model = DenseNet121(include_top=False, weights='imagenet', pooling='avg')\n",
        "orig_model = tf.keras.applications.InceptionResNetV2(include_top=False, weights='imagenet', pooling='avg')\n",
        "inp = Input(shape = (128,128,3))\n",
        "x = orig_model(inp)\n",
        "# output1 = Dense(8, activation = 'sigmoid')(x)\n",
        "# output2 = Dense(14, activation = 'sigmoid')(x)\n",
        "# model = Model(inp,[output1,output2])\n",
        "output = Dense(20, activation='sigmoid')(x)\n",
        "model = Model(inp, output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Pud5RKBpFLY",
        "outputId": "24b87b09-d543-41f4-bf5c-828434411278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_resnet_v2 (Functio (None, 1536)              54336736  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 20)                30740     \n",
            "=================================================================\n",
            "Total params: 54,367,476\n",
            "Trainable params: 54,306,932\n",
            "Non-trainable params: 60,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT2Vwx2b0jvb"
      },
      "source": [
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=False)\n",
        "adam = tf.keras.optimizers.Adam(\n",
        "    learning_rate=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
        "    name='Adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og4QSnoJoLB8"
      },
      "source": [
        "model.compile(optimizer=adam, \n",
        "              loss = loss,\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISZ8_eFqszrR",
        "outputId": "ba6c0102-e8c6-4ff2-d762-9c2092f17052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "checkpoint_path = os.path.join(data_path, 'NIPA_pre.h5')\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create path if exists\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
        "else:\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
        "    \n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, monitor='val_sparse_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', min_delta=0.0001,patience=10)\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/DataCollection/NIPA2020 -- Folder already exists \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrl2_s2pC_gN",
        "outputId": "2b178a3f-fa19-4432-cb08-a23fc008592e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "\n",
        "model.fit_generator(\n",
        "    # generator=generator_wrapper(train_generator),\n",
        "    train_generator,\n",
        "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "    validation_data = validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=EPOCHS,verbose=1,\n",
        "                    callbacks=[cp_callback, earlystop_callback, reduce_lr]) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-260848254979>:11: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.4931 - sparse_categorical_accuracy: 0.8658 \n",
            "Epoch 00001: val_sparse_categorical_accuracy improved from -inf to 0.92000, saving model to /content/drive/My Drive/DataCollection/NIPA2020/NIPA_pre.h5\n",
            "400/400 [==============================] - 6775s 17s/step - loss: 0.4931 - sparse_categorical_accuracy: 0.8658 - val_loss: 0.2643 - val_sparse_categorical_accuracy: 0.9200\n",
            "Epoch 2/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1351 - sparse_categorical_accuracy: 0.9552\n",
            "Epoch 00002: val_sparse_categorical_accuracy improved from 0.92000 to 0.94063, saving model to /content/drive/My Drive/DataCollection/NIPA2020/NIPA_pre.h5\n",
            "400/400 [==============================] - 122s 306ms/step - loss: 0.1351 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.1954 - val_sparse_categorical_accuracy: 0.9406\n",
            "Epoch 3/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0971 - sparse_categorical_accuracy: 0.9666\n",
            "Epoch 00003: val_sparse_categorical_accuracy improved from 0.94063 to 0.95938, saving model to /content/drive/My Drive/DataCollection/NIPA2020/NIPA_pre.h5\n",
            "400/400 [==============================] - 122s 304ms/step - loss: 0.0971 - sparse_categorical_accuracy: 0.9666 - val_loss: 0.1669 - val_sparse_categorical_accuracy: 0.9594\n",
            "Epoch 4/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0696 - sparse_categorical_accuracy: 0.9763\n",
            "Epoch 00004: val_sparse_categorical_accuracy improved from 0.95938 to 0.96906, saving model to /content/drive/My Drive/DataCollection/NIPA2020/NIPA_pre.h5\n",
            "400/400 [==============================] - 122s 304ms/step - loss: 0.0696 - sparse_categorical_accuracy: 0.9763 - val_loss: 0.1330 - val_sparse_categorical_accuracy: 0.9691\n",
            "Epoch 5/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0535 - sparse_categorical_accuracy: 0.9814\n",
            "Epoch 00005: val_sparse_categorical_accuracy improved from 0.96906 to 0.97656, saving model to /content/drive/My Drive/DataCollection/NIPA2020/NIPA_pre.h5\n",
            "400/400 [==============================] - 121s 303ms/step - loss: 0.0535 - sparse_categorical_accuracy: 0.9814 - val_loss: 0.1016 - val_sparse_categorical_accuracy: 0.9766\n",
            "Epoch 6/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0489 - sparse_categorical_accuracy: 0.9830\n",
            "Epoch 00006: val_sparse_categorical_accuracy did not improve from 0.97656\n",
            "400/400 [==============================] - 119s 298ms/step - loss: 0.0489 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1276 - val_sparse_categorical_accuracy: 0.9603\n",
            "Epoch 7/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0486 - sparse_categorical_accuracy: 0.9839\n",
            "Epoch 00007: val_sparse_categorical_accuracy did not improve from 0.97656\n",
            "400/400 [==============================] - 118s 294ms/step - loss: 0.0486 - sparse_categorical_accuracy: 0.9839 - val_loss: 0.2294 - val_sparse_categorical_accuracy: 0.9400\n",
            "Epoch 8/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0224 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 00008: val_sparse_categorical_accuracy improved from 0.97656 to 0.98719, saving model to /content/drive/My Drive/DataCollection/NIPA2020/NIPA_pre.h5\n",
            "400/400 [==============================] - 121s 302ms/step - loss: 0.0224 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0559 - val_sparse_categorical_accuracy: 0.9872\n",
            "Epoch 9/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0142 - sparse_categorical_accuracy: 0.9962\n",
            "Epoch 00009: val_sparse_categorical_accuracy did not improve from 0.98719\n",
            "400/400 [==============================] - 118s 295ms/step - loss: 0.0142 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0765 - val_sparse_categorical_accuracy: 0.9853\n",
            "Epoch 10/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0112 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 00010: val_sparse_categorical_accuracy did not improve from 0.98719\n",
            "400/400 [==============================] - 117s 293ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0775 - val_sparse_categorical_accuracy: 0.9850\n",
            "Epoch 11/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0093 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 00011: val_sparse_categorical_accuracy did not improve from 0.98719\n",
            "400/400 [==============================] - 117s 293ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0776 - val_sparse_categorical_accuracy: 0.9853\n",
            "Epoch 12/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0090 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 00012: val_sparse_categorical_accuracy improved from 0.98719 to 0.98750, saving model to /content/drive/My Drive/DataCollection/NIPA2020/NIPA_pre.h5\n",
            "400/400 [==============================] - 121s 301ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0638 - val_sparse_categorical_accuracy: 0.9875\n",
            "Epoch 13/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0082 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 00013: val_sparse_categorical_accuracy did not improve from 0.98750\n",
            "400/400 [==============================] - 117s 293ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0728 - val_sparse_categorical_accuracy: 0.9847\n",
            "Epoch 14/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0093 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 00014: val_sparse_categorical_accuracy improved from 0.98750 to 0.98781, saving model to /content/drive/My Drive/DataCollection/NIPA2020/NIPA_pre.h5\n",
            "400/400 [==============================] - 120s 299ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0540 - val_sparse_categorical_accuracy: 0.9878\n",
            "Epoch 15/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0081 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 00015: val_sparse_categorical_accuracy did not improve from 0.98781\n",
            "400/400 [==============================] - 118s 295ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0544 - val_sparse_categorical_accuracy: 0.9878\n",
            "Epoch 16/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0075 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 00016: val_sparse_categorical_accuracy did not improve from 0.98781\n",
            "400/400 [==============================] - 117s 294ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0678 - val_sparse_categorical_accuracy: 0.9866\n",
            "Epoch 17/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0068 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 00017: val_sparse_categorical_accuracy did not improve from 0.98781\n",
            "400/400 [==============================] - 117s 293ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0654 - val_sparse_categorical_accuracy: 0.9872\n",
            "Epoch 18/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0079 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 00018: val_sparse_categorical_accuracy did not improve from 0.98781\n",
            "400/400 [==============================] - 117s 292ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0663 - val_sparse_categorical_accuracy: 0.9862\n",
            "Epoch 19/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0084 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 00019: val_sparse_categorical_accuracy did not improve from 0.98781\n",
            "400/400 [==============================] - 116s 291ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9875\n",
            "Epoch 20/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0081 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 00020: val_sparse_categorical_accuracy improved from 0.98781 to 0.98969, saving model to /content/drive/My Drive/DataCollection/NIPA2020/NIPA_pre.h5\n",
            "400/400 [==============================] - 120s 299ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0579 - val_sparse_categorical_accuracy: 0.9897\n",
            "Epoch 21/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0066 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 00021: val_sparse_categorical_accuracy did not improve from 0.98969\n",
            "400/400 [==============================] - 117s 292ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0862 - val_sparse_categorical_accuracy: 0.9841\n",
            "Epoch 22/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0095 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 00022: val_sparse_categorical_accuracy did not improve from 0.98969\n",
            "400/400 [==============================] - 117s 292ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0576 - val_sparse_categorical_accuracy: 0.9891\n",
            "Epoch 23/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0083 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 00023: val_sparse_categorical_accuracy did not improve from 0.98969\n",
            "400/400 [==============================] - 117s 291ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0623 - val_sparse_categorical_accuracy: 0.9869\n",
            "Epoch 24/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0093 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 00024: val_sparse_categorical_accuracy did not improve from 0.98969\n",
            "400/400 [==============================] - 116s 290ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0670 - val_sparse_categorical_accuracy: 0.9884\n",
            "Epoch 25/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0075 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 00025: val_sparse_categorical_accuracy did not improve from 0.98969\n",
            "400/400 [==============================] - 117s 292ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0593 - val_sparse_categorical_accuracy: 0.9866\n",
            "Epoch 26/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0078 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 00026: val_sparse_categorical_accuracy did not improve from 0.98969\n",
            "400/400 [==============================] - 115s 288ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0685 - val_sparse_categorical_accuracy: 0.9859\n",
            "Epoch 27/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0085 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00027: val_sparse_categorical_accuracy did not improve from 0.98969\n",
            "400/400 [==============================] - 115s 288ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0616 - val_sparse_categorical_accuracy: 0.9875\n",
            "Epoch 28/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0095 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 00028: val_sparse_categorical_accuracy did not improve from 0.98969\n",
            "400/400 [==============================] - 116s 290ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0677 - val_sparse_categorical_accuracy: 0.9875\n",
            "Epoch 29/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0094 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00029: val_sparse_categorical_accuracy did not improve from 0.98969\n",
            "400/400 [==============================] - 116s 291ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0638 - val_sparse_categorical_accuracy: 0.9869\n",
            "Epoch 30/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0070 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 00030: val_sparse_categorical_accuracy did not improve from 0.98969\n",
            "400/400 [==============================] - 117s 292ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0607 - val_sparse_categorical_accuracy: 0.9897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7d8c64a080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaIvDIpyYqC4",
        "outputId": "3d01135d-fffe-4506-8038-998bbbe07b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_df = pd.read_csv('/content/drive/My Drive/DataCollection/NIPA2020/test.tsv', sep='\\t', names= [\"file_name\"])\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  file_name\n",
              "0     0.jpg\n",
              "1     1.jpg\n",
              "2     2.jpg\n",
              "3     3.jpg\n",
              "4     4.jpg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGkgQ6FiYbuO"
      },
      "source": [
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm-p6SWyYjFc",
        "outputId": "a269940e-df3b-4bc2-f5f0-f8f6a8b9383e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "  dataframe=test_df,\n",
        "  directory=\"/content/drive/My Drive/DataCollection/NIPA2020/test\",\n",
        "  x_col=\"file_name\",\n",
        "  y_col=None,\n",
        "  # subset=\"validation\",\n",
        "  batch_size=BATCH_SIZE,\n",
        "  seed=seed,\n",
        "  shuffle=False,\n",
        "  class_mode=None,\n",
        "  target_size=(128,128))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3997 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcvraEpHhrgg"
      },
      "source": [
        "model.load_weights(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4k9q9-0oJ4m",
        "outputId": "6dda4e41-d32c-4604-abdb-d8a3bd8f703f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "test_generator.reset()\n",
        "pred=model.predict_generator(test_generator,\n",
        "  steps=300,\n",
        "  verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-2b2c788e06f9>:5: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n",
            "125/300 [===========>..................] - ETA: 34:06WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 300 batches). You may need to use the repeat() function when building your dataset.\n",
            "125/300 [===========>..................] - 1462s 12s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWtwNQS8L0PD",
        "outputId": "483ad2fe-6bd6-4c72-9b9c-b5b29545d7b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labellist = []\n",
        "for i in range(len(pred)):\n",
        "  answer = np.argmax(pred[i], axis=-1)\n",
        "  labellist.append(answer)\n",
        "len(labellist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XKw5J0OOq_E",
        "outputId": "cd9f2f65-a462-402a-c10e-2931b44a06dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_df['Plant'] = labellist\n",
        "test_df['Disease'] = labellist\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>Plant</th>\n",
              "      <th>Disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  file_name  Plant  Disease\n",
              "0     0.jpg      0        0\n",
              "1     1.jpg      1        1\n",
              "2     2.jpg      2        2\n",
              "3     3.jpg      3        3\n",
              "4     4.jpg      4        4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDoCthiKQTZ4"
      },
      "source": [
        "plant_dic = {0:3, 1:3, 2:4, 3:4, 4:4, 5:5, 6:7, 7:7, 8:8, \n",
        "             9:8, 10:10, 11:11, 12:13, 13:13, 14:13, 15:13, 16:13, 17:13, 18:13, 19:13}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ3QUDR1U7aC"
      },
      "source": [
        "dz_dic = {0:5, 1:20, 2:2, 3:7, 4:11, 5:8, 6:1, 7:20, 8:6, 9:9, 10:20, 11:14,\n",
        "                   12:1, 13:6, 14:9, 15:15, 16:16, 17:17, 18:18, 19:20}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TnCvl_AO6zm",
        "outputId": "484f5a8d-49ec-44a6-84b6-65d5fa1a56c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "plant_df = test_df.replace({'Plant':plant_dic})\n",
        "submit_df = plant_df.replace({'Disease':dz_dic})\n",
        "submit_df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>Plant</th>\n",
              "      <th>Disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  file_name  Plant  Disease\n",
              "0     0.jpg      3        5\n",
              "1     1.jpg      3       20\n",
              "2     2.jpg      4        2\n",
              "3     3.jpg      4        7\n",
              "4     4.jpg      4       11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS8gdW9uiKbp"
      },
      "source": [
        "submit_df.to_csv('/content/drive/My Drive/DataCollection/NIPA2020/submit.tsv', sep='\\t', index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVlahsjhalIz"
      },
      "source": [
        "# tf.keras.models.save_model(\n",
        "#     model, data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfZK24X4_uq2"
      },
      "source": [
        "# model.save('/content/drive/My Drive/DataCollection/NIPA2020/my_model.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6eAjEdmWhCj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}